#!/usr/bin/env python

# Copyright 2013: Emmanouil Kiagias <e.kiagias@gmail.com>
# License: GPL

"""
This script generates the control file used by the Blend task package.
"""

import os
import re
import sys
import argparse
import psycopg2
import logging
import pprint
import subprocess

#### UDD ####
UDDPORT=5452
DEFAULTPORT=5432

class UDD_connector:
    """
    This class connects with UDD and provides methods to query Blends' information
    """
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.connection = self.__get_db_connection()
        self.cursor = self.connection.cursor()

    def __get_db_connection(self):
        """
        Connects to UDD and return a cursor instance
        """
        ##TODO add additional connections in case of error (like different port)
        self.logger.debug("Trying to connect to UDD")
        try:
            conn = psycopg2.connect(host="localhost",port=UDDPORT,user="guest",database="udd")
        except psycopg2.OperationalError, err:
            try:
                conn = psycopg2.connect(host="udd.debian.org",port=UDDPORT,user="guest",database="udd")
            except psycopg2.OperationalError, err:
                self.logger.error("UDD connection error: {0}").format(err)
                sys.exit(-1)


        return conn

    def finish():
        """
        This method finalizes the db connection and the connected class' cursor
        """
        #FIXME add proper try catch
        self.cursor.close()
        self.connection.close()

    def __execute_query(self, query):
        """
        This function executes the given query and checks 
        if any error/exception occurs during the execution.
        """
        self.logger.debug("Executing query:\n{0}\n".format(query))

        try:
            self.cursor.execute(query)
        except psycopg2.ProgrammingError, err:
            self.logger.error("Problem with query\n{0}\n{1}".format(query, err))
            sys.exit(-1)
        except psycopg2.DataError, err:
            self.logger.error("{0}; query was\n{1}".format(err, query))
            sys.exit(-1)


    def get_available_releases(self):
        """
        It queries UDD and returns a list with with all the available releases(stable, testing etc)
        (for the moment is used for just checking the command line arguments, this function may be removed later)
        """
        query = "select distinct role from releases"

        self.__execute_query(query)

        #just check if any of the rows retured is empty
        return [ release[0] for release in self.cursor.fetchall() if release[0] ]

    def __get_available_architectures(self):
        """
        It queries the UDD and returns a list with all the available Debian architectures
        """
        query = "select distinct architecture from packages where architecture != 'all'"

        self.__execute_query(query)

        #just check if any of the rows retured is empty
        return [ arch[0] for arch in self.cursor.fetchall() if arch[0] ]

    def get_blend_info(self, blend):
        """
        Return a dictionary containing the given's blend info (title, description, vcs, taskprefix etc)
        """
        self.logger.debug("get_blend_info function was called")

        blend_info = {}    
        query="""
            SELECT * FROM blends_metadata WHERE blend='{0}'
            """.format(blend)

        self.__execute_query(query)

        #get the blend info from the cursor
        info = self.cursor.fetchone()

        ##TODO write a proper handling of invalid arguments(not existing blends, architecture etc)
        if not info:
            self.logger.error("Blend: {0} not found, aborting".format(blend))
            sys.exit(-1)

        #column name: 0 index of each desc list element
        desc = self.cursor.description

        for i, column in enumerate(desc):
            blend_info[column[0]] = info[i]

        return blend_info

    def __get_tasks_info(self, **kwargs):
        """
        Return a dictionary containing the tasks' info(title, description, section, priority etc) for the given blend
        """
        self.logger.debug("__get_task_info function was called")

        blendname = kwargs["blend"]
        tasksprefix = kwargs["tasksprefix"]
        release = kwargs["release"]

        blends_dependencies = {}

        query="""
            SELECT task, description, section as "Section", enhances as "Enhances", leaf as "Leaf",
                  metapackage, test_always_lang, long_description
                FROM blends_tasks
            WHERE blend='{0}'
            """.format(blendname)

        self.__execute_query(query)

        desc = self.cursor.description

        #loop over each result in cursor's results set
        result = self.cursor.fetchone()

        while not result is None:
            #result row indexes: task(0), title(1), metapackage(2), description(3), long_description(4)
            task = result[0]

            blends_dependencies[task] = {}
            blends_dependencies[task]['haspackages'] = 0

            self.logger.debug("Reading info about task: {0}".format(task))

            #we want desc[1:] we dont want the 0 index which contains the task name
            #column[0] contains the column name(taken from cursor description)
            for i, column in enumerate(desc[1:]):
                #results[i+1] cause we start from index 1 (desc[1:]) and not from 0
                blends_dependencies[task][column[0]] = result[i+1]

            #the proposed priority is extra for all Blends
            blends_dependencies[task]["Priority"] = "extra"

            #also initialize empty lists for the following keys:
            for key in ["Depends", "Recommends", "Suggests", "Ignores", "Avoid"]:
                blends_dependencies[task][key] = []
            
            result = self.cursor.fetchone()
            
        return blends_dependencies


    def __build_all_architectures_query(self, blend, release, architectures):
        """
        Builds up a query to check each blends_dependency for each available
        Debian architecture
        """

        select_clause = """
           SELECT b.task, b.alternatives, b.dependency, b.distribution, b.component, b.contains_provides 
           """

        from_clause = """
            FROM blends_dependencies_alternatives b
            """

        where_clause = """
        WHERE b.blend='{0}'
        """.format(blend)


        for arch in architectures:
            select_clause += ", pkg_{0}.architecture".format(arch.replace('-',''))

            from_clause += """
                LEFT OUTER JOIN ( 
                 SELECT p.package, p.architecture 
                   FROM packages p JOIN releases r ON p.release = r.release 
                   WHERE r.role='{0}' and architecture='{1}') pkg_{2} ON b.alternatives = pkg_{2}.package
            """.format(release, arch, arch.replace('-',''))

        return select_clause + from_clause + where_clause

    def __build_alternatives_query(self, alternatives, release, architectures):
        formatted_alternatives = [  "'{0}'".format(pkg) for pkg in set(alternatives) ]
        formatted_architectures = [ "'{0}'".format(arch) for arch in architectures ] 

        #this query is done this way, because we want first to get the packages for debian/main and then check if they 
        #exist in a specific set of architectures and a specific release. if they are debian/main and they do not exist for 
        #any architecture then do not include them into the Suggests
        query = """
           SELECT distinct p.package, pkg.architecture FROM packages p 
            LEFT OUTER JOIN 
            ( SELECT distinct mp.package, mp.architecture FROM packages mp JOIN releases r ON mp.release = r.release
                        WHERE mp.package in ( {0} ) AND mp.architecture in ( {1} ) AND mp.distribution='debian' 
                         AND mp.component='main' AND r.role='{2}' ) pkg on p.package = pkg.package 
            WHERE p.package in ( {0} ) AND p.distribution='debian' AND p.component='main'
            """.format(','.join(formatted_alternatives), ','.join(formatted_architectures), release)
        
        return query

    def __get_available_alternatives(self, alternatives, release, architectures):
        query = self.__build_alternatives_query(alternatives, release, architectures + ["all"])

        available_packages = {}

        self.__execute_query(query)

        #package value in index 0 and architecture value in index 1
        row = self.cursor.fetchone()
        while not row is None:
            pkg_temp = row[0]
            arch_temp = row[1]

            if not pkg_temp in available_packages:
                available_packages[pkg_temp] = []

            if arch_temp:
                available_packages[pkg_temp].append(arch_temp)

            row = self.cursor.fetchone()

        return available_packages

    def __build_virtuals_query(self, virtual_packages, release, architectures):
        formatted_architectures = [ "'{0}'".format(arch) for arch in architectures ]

        query = """
          SELECT distinct p.provides, p.architecture FROM packages p JOIN releases r ON p.release = r.release
          WHERE r.role='{0}' AND p.distribution='debian' AND component='main' AND p.architecture in ( {1} )
            AND provides ~ ('((\s|,)'||'({2})'||'(\s+|,|$)|^'||'({2})'||'$)')
        """.format(release, ','.join(formatted_architectures), '|'.join(virtual_packages))

        return query

    def __get_available_virtuals(self, virtual_packages, release, architectures):
        query_provides = self.__build_virtuals_query(virtual_packages, release, architectures + ["all"])
        self.__execute_query(query_provides)

        available_provides = {}

        #populate available_provides dict
        #package value in index 0 and architecture value in index 1
        row = self.cursor.fetchone()
        while not row is None:
            pkg_temp_list = [ p.strip() for p in row[0].split(',') ]
            myarch = row[1]
            for p in pkg_temp_list:
                if not p in available_provides:
                    available_provides[p] = []

                available_provides[p].append(myarch)
            
            row = self.cursor.fetchone()

        return available_provides

    def __resolve_architectures(self, exist_in_architectures, architectures):
        """
        return [ !arch1 !arch2 !arch3 ] as a string for the architecture differences between the given architectures list
        """

        if len(exist_in_architectures) == 1 and exist_in_architectures[0] == "all":
            return ''

        missing_archs = set(architectures) - set(exist_in_architectures)

        if missing_archs:
            excluded = []
            for missing in missing_archs:
                excluded.append('!' + missing)

            return ' [' + ' '.join(excluded) + ']'
        else:
            return '' 

    def get_blend_dependecies(self, **kwargs):
        """
        Using the given arguments queries UDD and returns a dictionary containing
        all the blends' tasks dependencies
        """
        self.logger.debug("get_blend_dependecies function was called.")

        blend = kwargs["blend"]
        release = kwargs["release"]
        nodepends = kwargs["nodepends"]
        taskdescription = kwargs['taskdescription']

        #initialize the tasks' info before getting the dependencies for the tasks
        blend_dependencies = self.__get_tasks_info(blend = blend, release = release, tasksprefix = kwargs["tasksprefix"])
        
        architectures = self.__get_available_architectures()

        blend_alternatives_virtuals = {}
        single_alternatives_list = []
        virtual_packages = []
        available = []
        missing = set()
        excluded = []

        wanted_dependencies = []
        if nodepends or taskdescription:
            wanted_dependencies += ['d', 'r']
        else:
            wanted_dependencies.append('d')

        query = self.__build_all_architectures_query(blend, release, architectures + ["all"] )

        self.__execute_query(query)
        
        #indexes of row: task(0), package(1), dependency(2), distribution(3), component(4), p.contains_provides(5)
        #the rest are architectures
        row = self.cursor.fetchone()

        while not row is None:
            #task, package, dependency, distribution, component, provides = (row[0], row[1], row[2], row[3], row[4], row[5], row[6])
            task, package, dependency, distribution, component, contains_provides = row[:6]
            exist_in_archs = [ x for x in row[6:] if x ]

            if not dependency == 'i' and not dependency == 'a':
                blend_dependencies[task]["haspackages"] += 1

            #check for alternatives('|') and virtuals(provides)
            #if a Depends-virtual does not exist into an alternative relation, let it be
            #it will go into Suggests cause it will not have any element into exist_in_archs
            if '|' in package:
                #no need to handle alternatives or virtual which are not Debian,main
                #because they will go into Suggests if they are Depends/Recommends
                ###TODO check this out again
                #if dependency in wanted_dependencies and distribution == 'debian' and component == 'main':
                if dependency in wanted_dependencies:
                    #TODO check again, do not include at all virtual packages when it comes to the tasksel template file
                    if contains_provides and not taskdescription:
                        virtual_packages += [ myalt.strip() for myalt in package.split("|") ]

                    if not task in blend_alternatives_virtuals:
                        blend_alternatives_virtuals[task] = []
                    
                    blend_alternatives_virtuals[task].append(package)
                    single_alternatives_list += [ myalt.strip() for myalt in package.split("|")]

                    row = self.cursor.fetchone()
                    continue

            #TODO check again if: if else is with proper syntax
            if nodepends or taskdescription:
                #in this case all the Depends go to Recommends and the recommend packages
                #follow the same rules as the depends packages
                #dependency 'd'== depends and 'r' == recommends
                if dependency == 'd' or dependency == 'r':
                    if distribution == 'debian' and component == 'main':
                        #here also note that stand-alone virtual packages will provide an empty exist_in_archs
                        #so they correctly be added to Suggests (handles properly the virtual-package-depends-without-real-package-depends problem)
                        if exist_in_archs:
                            archs_resolved = self.__resolve_architectures(exist_in_archs, architectures)
                            blend_dependencies[task]["Recommends"].append(package + archs_resolved)
                        elif not exist_in_archs and contains_provides:
                            blend_dependencies[task]["Suggests"].append(package)
                        else:
                            #a debian/main package which does not exist for any arch then 
                            #it's a candidate for updated name/version inside name
                            missing.add(package)
                    else:
                        blend_dependencies[task]["Suggests"].append(package)
            else:
                if dependency == 'd':
                    if distribution == 'debian' and component == 'main':
                        if exist_in_archs:
                            archs_resolved = self.__resolve_architectures(exist_in_archs, architectures)
                            blend_dependencies[task]["Depends"].append(package + archs_resolved)
                        elif not exist_in_archs and contains_provides:
                            blend_dependencies[task]["Suggests"].append(package)
                        else:
                            #a debian/main package which does not exist for any arch then 
                            #it's a candidate for updated name/version inside name
                            missing.add(package)
                    else:
                        blend_dependencies[task]["Suggests"].append(package)
                elif dependency == 'r':
                    blend_dependencies[task]["Recommends"].append(package)

            if dependency == 's':
                blend_dependencies[task]["Suggests"].append(package)
            if dependency == 'i':
                blend_dependencies[task]["Ignores"].append(package)
                #missing.append(package)
            if dependency == 'a':
                blend_dependencies[task]["Avoid"].append(package)
                excluded.append(package)

            #TODO check which packages should be kept
            #not sure if i should add these packages into the missing
            #if not distribution == 'debian' or not component == 'main' or not exist_in_archs:
            #    missing.append(package)
            #else:
            #    available.append(package)

            row = self.cursor.fetchone()

        ## Up to this point we have properly handled all the single stand-alone packages
        ## now its time to also handle the alternatives(+ virtuals)
        if blend_alternatives_virtuals:
            available_packages = self.__get_available_alternatives(single_alternatives_list, release, architectures + ["all"])
            available_provides = {}

            if virtual_packages:
                available_provides = self.__get_available_virtuals(virtual_packages, release, architectures + ["all"])

            for task in blend_alternatives_virtuals:
                alternatives_list = blend_alternatives_virtuals[task]
                for alternative in alternatives_list:
                    increase_packages = True

                    single_alt_exist_temp, single_alt_missing = self.__get_resolved_alternatives(alternative, available_packages, available_provides)

                    single_alt_exist = []

                    for tmp in single_alt_exist_temp:
                        if tmp in available_packages:
                            archs_exist = available_packages[tmp]
                            #if exists into debian/main but its not available for 
                            #any architecture just skip it, do not include it in Suggests
                            if not archs_exist:
                                continue
                        elif tmp in available_provides:
                            archs_exist = available_provides[tmp]

                        single_alt_exist.append(tmp + self.__resolve_architectures(archs_exist, architectures))

                    if nodepends or taskdescription:
                        if single_alt_exist:
                            blend_dependencies[task]["Recommends"].append(' | '.join(single_alt_exist))
                        if single_alt_missing:
                            blend_dependencies[task]["Suggests"].append(' | '.join(single_alt_missing))
                    else:
                        if single_alt_exist:
                            blend_dependencies[task]["Depends"].append(' | '.join(single_alt_exist))
                        if single_alt_missing:
                            blend_dependencies[task]["Suggests"].append(' | '.join(single_alt_missing))

                    #TODO check again which packages should go into the missing and which should go into available
                    if single_alt_missing:
                       missing = missing.union(set(single_alt_missing))
                    #if single_alt_exist_temp:
                    #    available += single_alt_exist_temp

        ##TODO, available is empty, check with debian-edu people if they need it
        return ( blend_dependencies, available, list(missing), excluded )


    ## TODO rewrite less dirty
    def __get_resolved_alternatives(self, alternative, available_packages, available_provides):
        single_alt_exist = []
        single_alt_missing = []

        alt_list = [ alt.strip() for alt in alternative.split('|') ]
        at_least_one_real = False
        at_least_one_virtual = False

        for single_alt in alt_list:
            if single_alt in available_packages:
                if not at_least_one_real:
                    at_least_one_real = True
                    #true if it's a real package
                single_alt_exist.append({ "value" : single_alt, "real" : True})

            elif single_alt in available_provides:
                if not at_least_one_virtual:
                    at_least_one_virtual = True
                #if not single_alt in single_alt_exist:
                #false if it's a virtual package
                not_defined = True
                for x in single_alt_exist:
                    if single_alt == x["value"]:
                        not_defined = False
                        break
                if not_defined:
                    single_alt_exist.append({ "value" : single_alt, "real" : False})
            else:
                single_alt_missing.append(single_alt)

        single_alt_exist_list = []

        ##http://lintian.debian.org/tags/virtual-package-depends-without-real-package-depends.html
        if not at_least_one_real:
            single_alt_exist = []
            single_alt_missing = alt_list
        else:
            if at_least_one_virtual:
                reals_temp = []
                for pkg in single_alt_exist:
                    if pkg["real"]:
                        reals_temp.append(pkg["value"])

                virtuals_temp = list(set([ x["value"] for x in single_alt_exist]) - set(reals_temp))
                single_alt_exist_list = reals_temp + virtuals_temp

        if not single_alt_exist_list:
            single_alt_exist_list = [ x["value"] for x in single_alt_exist]

        
        return single_alt_exist_list, single_alt_missing


    def warn_for_updated_packages(self, missing, release):
        """
        This function takes a list with missing(no arch available for them) packages
        and checks if the packages where updated(and maybe their name changed) thus their
        they are were not found. replace column from packages UDD table will be checked 
        """

        query = """
        SELECT distinct p.package, p.replaces FROM packages p JOIN releases r ON p.release = r.release 
            WHERE r.role='{1}' AND replaces ~ ('((\s|,)'||'({0})'||'(\s+|,|$)|^'||'({0})'||'$)')
        """.format('|'.join(missing),release)


        self.__execute_query(query)

        row = self.cursor.fetchone()
        while not row is None:
            new_package, replaced = row

            replaced = replaced.replace(',', ' ').replace('|', ' ')
            # Remove versions from versioned depends
            replaced = re.sub('\(.*\)', '', replaced)

            single_replaced = []
            for x in replaced.split(' '):
                stripped = x.strip()

                if stripped:
                   single_replaced.append(stripped) 

            for mis in missing:
                if mis in single_replaced:
                    self.logger.warning('"{0}" has been replaced with "{1}"'.format(mis, new_package))

            row = self.cursor.fetchone()


    def warn_embedded_version_packages(self, missing, release):
        #search for packages containing number(probably versions) into their names
        regex = re.compile('.*\d.*')
        
        #select distinct package, regexp_replace(package, '\d', '', 'g') from packages where package like '%sugar-artwork%' order by package;

        regex_clause = []
        packages_keys = {}
        for pkg in missing:
            for match in [ regex.search(pkg) ]:
                if match:
                    matched_pkg = match.group(0)
                    #replace all numbers(versions) from the package
                    #ext2-modules-8.1-1-amd64-di --> ext\d*-modules-\d*.\d*-\d*-amd\d*\d*-di
                    regex_clause.append( re.sub('\d', '\d*.?\d*', matched_pkg))

                    #keep a dict like { "ext-modules---amd-di" : "ext2-modules-8.1-1-amd64-di" }
                    packages_keys[re.sub('\d|\.', '',matched_pkg)] = matched_pkg

        query = """
                SELECT DISTINCT p.package, regexp_replace(p.package , '\d|\.', '', 'g')
                 FROM packages p JOIN releases r ON p.release = r.release 
                WHERE r.role='{1}' AND p.package ~ '{0}' order by p.package""".format('|'.join(regex_clause), release)

        results = {}

        self.__execute_query(query)

        row = self.cursor.fetchone()
        while not row is None:
            candidate_pkg, pkg_key = row 

            if not pkg_key in results:
                results[pkg_key] = []

            results[pkg_key].append(candidate_pkg)

            row = self.cursor.fetchone()

        for pkg_key in packages_keys:
            if pkg_key in results:
                self.logger.warning(" **Missing package {0} has the following existing versions:".format(packages_keys[pkg_key]))
                self.logger.warning(", ".join(results[pkg_key]))

def gen_control(**kwargs):
    """
    This method generates the blend's control file using the dataDict which contains 
    the blends' info along with all the blends dependencies
    """
    logger = logging.getLogger(__name__)
    logger.debug("gen_control method was called")

    #get the data we need from kwargs
    hasconfig = kwargs["hasconfig"]
    suppressempty = kwargs["suppressempty"]
    nodepends = kwargs["nodepends"]
    tasksprefix = kwargs["blend_info"]["tasksprefix"]
    blend_dependencies = kwargs["blend_dependencies"]
    architecture = "any"

    #TODO this is used for testing for the moment, will be changed
    control_path = "control-sec.temp"
    logger.debug("Opening file {0} to write".format(control_path))
    with open(control_path,'w') as fout:

        for task in sorted(blend_dependencies.keys()):
            
            if not blend_dependencies[task]["metapackage"]:
                continue

            logger.debug("{0}: {1}".format(task, blend_dependencies[task]["haspackages"]))

            #if no package was found in the target distribution suppress this task at all
            if suppressempty and blend_dependencies[task]["haspackages"] == 0:
                logger.debug("The metapackage {0} will not be created because {1} dependant are in the pool and suppressempty was set {2}".format(task, blend_dependencies[task]["haspackages"], suppressempty))
                continue

            fout.write("Package: {0}-{1}\n".format(tasksprefix, task))
            fout.write("Architecture: {0}\n".format(architecture))

            for header in ["Section", "Priority"]:
                if blend_dependencies[task][header]:
                    fout.write("{0}: {1}\n".format(header, blend_dependencies[task][header]))

            if nodepends:
                #Degrade dependencies to recommends
                fout.write("Depends: {0}-tasks (= ${{binary:Version}})".format(tasksprefix))

                if hasconfig:
                    fout.write(", {0}-config (= ${{binary:Version}})".format(tasksprefix))

                fout.write("\n")

                #TODO current blends-dev does a sort_uniq in case there are duplicates, also check if they exist
                fout.write("Recommends: {0}\n".format(",\n ".join(sorted(blend_dependencies[task]["Recommends"]))))

                if blend_dependencies[task]["Suggests"]:
                    fout.write("Suggests: {0}\n".format(",\n ".join(sorted(blend_dependencies[task]["Suggests"]))))

            else:
                for header in ["Depends", "Recommends", "Suggests"]:
                    if blend_dependencies[task][header]:
                        fout.write("{0}: {1}\n".format(header, ",\n ".join(sorted(blend_dependencies[task][header]))))

            fout.write("Description: {0}\n".format(blend_dependencies[task]["description"]))
            fout.write("{0}".format(blend_dependencies[task]["long_description"])) #Already contains a newline

            fout.write("\n")

def gen_task_desc(**kwargs):
    """
    This method generates the task description file for tasksel
    """
    logger = logging.getLogger(__name__)

    suppressempty = kwargs["suppressempty"]
    blend = kwargs["blend_info"]["blend"]
    tasksprefix = kwargs["blend_info"]["tasksprefix"]
    blend_dependencies = kwargs["blend_dependencies"]


    #TODO this is used for testing for the moment, will be changed
    task_desc_path = "taskdesc-sec.template"
    logger.debug("Opening file {0} to write".format(task_desc_path))
    with open(task_desc_path,'w') as fout:

        for task in sorted(blend_dependencies.keys()):    

            if blend_dependencies[task]['Leaf'] == 'false':
                continue

            if suppressempty and blend_dependencies[task]["haspackages"] == 0:
                if blend_dependencies[task]['test_always_lang']:
                    logger.debug("Print empty task {0} because Test-always-lang is set\n".format(task))
                else:
                    logger.debug("The metapackage {2} will not be created because {0} dependant are in the pool and suppressempty was set {1}\n".format(blend_dependencies[task]["haspackages"], suppressempty, task))
                    continue

            fout.write("Task: {0}-{1}\n".format(tasksprefix, task))
            fout.write("Section: {0}\n".format(blend));
            fout.write("Description: {0}\n".format(blend_dependencies[task]["description"]))
            fout.write("{0}".format(blend_dependencies[task]["long_description"])) #Already contains a newline
            fout.write("Relevance: 10\n")

            if blend_dependencies[task]["Enhances"]:
                fout.write("Enhances: {0}\n".format(blend_dependencies[task]["Enhances"]))

            if blend_dependencies[task]["metapackage"]:
                #No use listing a metapackage as a key package, if no metapackage exist.
                fout.write("Key: \n");
                fout.write(" {0}-{1}\n".format(tasksprefix, task))

            fout.write("Packages: list\n ")
            for header in ["Depends", "Recommends"]:
                if not blend_dependencies[task][header]:
                    continue     
                fout.write("{0}".format("\n ".join(sorted(blend_dependencies[task][header]))))
                fout.write("\n")

            fout.write("\n")

def main():
    blend_dev_dir = "/usr/share/blends-dev/"
    default_release = "testing"

    parser = argparse.ArgumentParser(epilog="Example: ./blend-gen-control -b debian-med -a amd64 --debug")
    #TODO this argument is kept for local testing
    parser.add_argument("-b", "--blend", dest="blend", type=str,
                        help="Blend name")
    parser.add_argument("-r", "--release", dest="release", type=str, default=default_release,
                        help="Target release, eg: stable, testing etc, default is: testing")
    parser.add_argument("-D", dest="nodepends", action="store_true", default=False,
                        help="lower all Depends: to Recommends:")
    parser.add_argument("-S", dest="suppressempty", action="store_true", default=False,
                        help="suppress tasks without any recommended package")
    parser.add_argument("-c", dest="gencontrol", action="store_true", default=False,
                        help="Create new debian/control file.")
    parser.add_argument("-t", dest="taskdesc", action="store_true", default=False,
                        help="Print task descriptions and package list for task")
    parser.add_argument("-w", "--warn-missing", dest="warn", action="store_true", default=False,
                        help="Print warning message with missing packages which are actually available packages with outdated name")

    parser.add_argument("-d", "--debug", dest="debug", action="store_true", default=False,
                        help="Print debug information")
    #parse the command line arguments
    args = parser.parse_args()

    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig()
    logger = logging.getLogger(__name__)
    #----------------------------end of argparse and setup logging--------------------------------------#

    if not args.blend:
        command = blend_dev_dir+"blend-get-names blendname"
        process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)
        output = process.communicate()[0].strip()
        if process.returncode != 0:
            logger.error(output)
            logger.error("For testing you can provide the desired blend through -b argument")
            sys.exit(-1)
        else:
            blendname = output
    else:
        blendname = args.blend

    #at least a -c or -t argument must be provided
    if not args.gencontrol and not args.taskdesc:
        logger.error("Argument -c(generate control file) or -t(generate taskdescription file) is required.")
        sys.exit(-1)

    hasconfig = False
    config_file = "config/control"

    myudd = UDD_connector()


    #check if the arg release provided from the user is valid
    if not args.release  == default_release:
        if args.release not in myudd.get_available_releases():
            logger.error("Invalid release: {0}, aborting..".format(args.release))
            sys.exit(-1)

    #check if a config file exists
    if os.path.isfile(config_file):
        hasconfig = True

    release = args.release
    suppressempty = args.suppressempty
    nodepends = args.nodepends

    blend_info = myudd.get_blend_info(blendname)
   
    if args.gencontrol:
        #generate a single control file
        #get all the blends dependencies etc
        blend_dependencies, available, missing, excluded = myudd.get_blend_dependecies(blend = blend_info["blend"], release = release, 
            tasksprefix = blend_info["tasksprefix"], nodepends = nodepends, taskdescription = False)

        gen_control(blend_info = blend_info, blend_dependencies = blend_dependencies,
            suppressempty = suppressempty, nodepends = nodepends, hasconfig = hasconfig)

    elif args.taskdesc:
        #we reuse the same code as above here BUT we need the blend_dependencies here without nodepends so we make sure we call it
        #with nodepends = False no matter the command line argument, no need to descrease depends to recommends in any way for task description
        blend_dependencies, available, missing, excluded = myudd.get_blend_dependecies(blend = blend_info["blend"], release = release, 
            tasksprefix = blend_info["tasksprefix"], nodepends = False, taskdescription = True)
        
        gen_task_desc(blend_info = blend_info, blend_dependencies = blend_dependencies,
            suppressempty = suppressempty)

    #warn the user in case you find packages with updated names so that's why they seem missing
    if args.warn:
        myudd.warn_for_updated_packages(missing, release)
        myudd.warn_embedded_version_packages(missing,release)
    return 0

if __name__ == '__main__':
    main()